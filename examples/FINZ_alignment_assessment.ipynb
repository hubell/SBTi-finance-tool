{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title_header",
   "metadata": {},
   "source": "# FINZ Alignment Assessment — Entity-Level Climate Alignment\n\nThis notebook performs a **FINZ (Financial Institution Net-Zero) alignment assessment** at the entity level. It takes your portfolio of entities/projects/assets and auto-populates FINZ alignment status using the **SBTi Companies Taking Action (CTA) database**.\n\n---\n\n## What This Notebook Does\n\n1. **Loads your portfolio** with entity identifiers and exposure values\n2. **Looks up each entity** in the SBTi CTA database (LEI → ISIN → Company Name waterfall)\n3. **Auto-populates assessment fields**: methodology, assessed metric, version, data source, and FINZ status\n4. **Respects user overrides**: any assessment values you provide in the input file are preserved\n5. **Flags submission readiness**: checks whether all FINZ target submission fields are complete\n6. **Groups results by financial activity** with segment (A/B/C/D) breakdown (when provided)\n\n---\n\n## FINZ Status Definitions\n\n| FINZ Status | Definition | Auto-Assigned? |\n|-------------|------------|----------------|\n| **In Transition** | 1.5°C validated SBTi target | Yes |\n| **Assessed** | Has SBTi target but not 1.5°C (WB2°C, 2°C, etc.) | Yes |\n| **Not Aligned** | No SBTi target found | Yes (default for unmatched) |\n| **Climate Solution** | Taxonomy-aligned climate solution | No (user override only) |\n\n---\n\n## Segment Mapping (A/B/C/D)\n\nPer FINZ Standard tables 1.1–1.5, entities are mapped to segments by financial activity:\n\n| Segment | Description |\n|---------|-------------|\n| **A** | High-impact sectors requiring sector-specific targets |\n| **B** | Other sectors with available methodologies |\n| **C** | Sectors with limited methodology coverage |\n| **D** | Special categories (e.g., project finance, real estate) |\n\nSegments are **user-provided** in the input file. The notebook validates they are A/B/C/D.\n\n---\n\n## Input Format\n\n### To Run the Assessment (minimum required)\n\nYou need **at least one identifier** per entity plus an exposure value:\n\n| Column | Required | Description | Example |\n|--------|----------|-------------|--------|\n| `company_name` | At least one of name/isin/lei | Entity/project/asset name | \"Greenleaf Foods Corp\" |\n| `isin` | At least one of name/isin/lei | ISIN identifier | \"XX0000000101\" |\n| `lei` | At least one of name/isin/lei | LEI identifier | \"549300AAAABBBBCCCC01\" |\n| `investment_value` | Yes | Investment/exposure amount | 1000000 |\n\nThe notebook will run with just these fields and produce a full FINZ assessment.\n\n### For FINZ Target Submission (all required)\n\nTo submit a FINZ target, **all** of the fields below must be populated. The notebook flags any that are missing or incomplete — but it will still run the assessment regardless.\n\n| Column | Description | Example |\n|--------|-------------|--------|\n| `company_name` | Entity/project/asset name | \"Greenleaf Foods Corp\" |\n| `isin` | ISIN identifier | \"XX0000000101\" |\n| `lei` | LEI identifier | \"549300AAAABBBBCCCC01\" |\n| `asset_class` | Per FINZ Standard tables 1.1–1.5 | \"Listed Equity\" |\n| `sector` | ICS code (GICS/NICS/ISIC) or sector name | \"D35\" or \"Utilities\" |\n| `financial_activity` | Lending, Asset Owner Investing, etc. | \"Lending\" |\n| `segment` | A/B/C/D per financial activity | \"A\" |\n| `investment_value` | Investment/exposure amount | 1000000 |\n\n### Assessment Override Fields (optional)\n\nThese are auto-populated by the SBTi CTA lookup. Provide values to override the defaults:\n\n| Column | Auto-default | Description |\n|--------|-------------|-------------|\n| `methodology_used` | \"SBTi Target Status\" | Override: assessment methodology |\n| `methodology_version` | \"SBTi CTA {date}\" | Override: version of methodology |\n| `data_source` | \"SBTi Companies Taking Action Database\" | Override: data source |\n| `finz_status` | Derived from CTA lookup | Override: e.g., \"Climate Solution\" |\n\n**Override behavior**: If you provide any of these in your input, those values are preserved as-is. Only blank cells get auto-populated.\n\n---\n\n## How to Use\n\n1. **Run the Setup** cell below\n2. **Upload your data** (or use the sample data)\n3. **Set the analysis date**\n4. **Run All Cells** — the notebook runs the CTA lookup, flags submission readiness, and generates summaries\n5. **Download the Excel output** with full assessment results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SETUP - Run this cell first\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "\n",
    "# Detect environment and install/import accordingly\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"  GOOGLE COLAB ENVIRONMENT DETECTED\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nInstalling SBTi Finance Tool...\")\n",
    "    !pip install -q sbti-finance-tool\n",
    "    print(\"Installation complete\")\n",
    "else:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"  LOCAL/JUPYTER ENVIRONMENT DETECTED\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nUsing locally installed packages\")\n",
    "    print(\"Tip: Run 'pip install sbti-finance-tool' if not installed\")\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Suppress common warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"\\nAll packages loaded successfully\")\n",
    "print(f\"\\nEnvironment: {'Google Colab' if 'google.colab' in sys.modules else 'Local/Jupyter'}\")\n",
    "print(\"Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample_data_md",
   "metadata": {},
   "source": [
    "## Download Sample Data\n",
    "\n",
    "This cell downloads example FINZ portfolio data so you can test the notebook. Skip this if using your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample_data_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample FINZ portfolio data\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "if not os.path.isfile(\"data/example_finz_portfolio.csv\"):\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://github.com/ScienceBasedTargets/SBTi-finance-tool/raw/main/examples/data/example_finz_portfolio.csv\",\n",
    "        \"data/example_finz_portfolio.csv\"\n",
    "    )\n",
    "    print(\"Sample FINZ data downloaded to data/example_finz_portfolio.csv\")\n",
    "else:\n",
    "    print(\"Sample FINZ data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_portfolio_md",
   "metadata": {},
   "source": [
    "## USER INPUT: Load Your Portfolio\n",
    "\n",
    "### Option 1: Use Sample Data (Default)\n",
    "Just run the next cell as-is to use the included example FINZ portfolio.\n",
    "\n",
    "### Option 2: Use Your Own Data\n",
    "\n",
    "**Google Colab:**\n",
    "1. Click the folder icon in the left sidebar\n",
    "2. Navigate to `data/` folder\n",
    "3. Drag and drop your CSV or Excel file\n",
    "4. Update the filename in the cell below\n",
    "\n",
    "**Local/Jupyter:**\n",
    "1. Copy your file to the `examples/data/` folder\n",
    "2. Update the filename in the cell below\n",
    "\n",
    "**Supported formats:** `.csv`, `.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_portfolio_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD PORTFOLIO DATA\n",
    "# =============================================================================\n",
    "\n",
    "# --- SAMPLE DATA (default) ---\n",
    "df_portfolio = pd.read_csv(\"data/example_finz_portfolio.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# --- YOUR OWN DATA ---\n",
    "# Uncomment ONE of the lines below and update the filename:\n",
    "#\n",
    "# For CSV files:\n",
    "# df_portfolio = pd.read_csv(\"data/YOUR_FILE.csv\", encoding=\"utf-8\")\n",
    "#\n",
    "# For Excel files:\n",
    "# df_portfolio = pd.read_excel(\"data/YOUR_FILE.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "print(f\"Loaded portfolio file successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standardize_columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names to snake_case (handles different naming formats)\n",
    "def convert_to_snake_case(name):\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    s2 = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1)\n",
    "    s3 = s2.lower()\n",
    "    s4 = re.sub(r'[^a-z0-9_]', '_', s3)\n",
    "    s5 = re.sub(r'_+', '_', s4)\n",
    "    return s5.strip('_')\n",
    "\n",
    "df_portfolio.columns = [convert_to_snake_case(col) for col in df_portfolio.columns]\n",
    "print(f\"Loaded {len(df_portfolio)} entities from portfolio\")\n",
    "print(f\"Columns found: {list(df_portfolio.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate_portfolio",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# VALIDATE PORTFOLIO DATA\n# =============================================================================\n\n# ---- 1. CTA Lookup Requirement (must pass to proceed) ----\n# The technical minimum: at least one identifier per entity for the SBTi CTA lookup.\n\nid_cols = [c for c in ['company_name', 'isin', 'lei'] if c in df_portfolio.columns]\n\nif not id_cols:\n    raise ValueError(\n        \"ERROR: No identifier columns found. \"\n        \"Your file needs at least one of: company_name, isin, lei\"\n    )\n\n# Check each row has at least one non-null identifier\nhas_id = df_portfolio[id_cols].notna().any(axis=1)\nrows_without_id = (~has_id).sum()\n\nprint(\"=\" * 70)\nprint(\"  CTA LOOKUP VALIDATION\")\nprint(\"=\" * 70)\n\nif rows_without_id > 0:\n    print(f\"\\n  WARNING: {rows_without_id} row(s) have no identifier (company_name/isin/lei).\")\n    print(f\"  These rows cannot be assessed against the CTA and will be skipped.\")\n    df_portfolio = df_portfolio[has_id].copy()\n    print(f\"  Continuing with {len(df_portfolio)} valid entities.\")\nelse:\n    print(f\"\\n  All {len(df_portfolio)} entities have at least one identifier.\")\n\n# Show identifier coverage\nfor col in id_cols:\n    populated = df_portfolio[col].notna().sum()\n    print(f\"    {col:<25} {populated}/{len(df_portfolio)} populated\")\n\nprint(f\"\\n  CTA lookup ready.\")\n\n\n# ---- 2. FINZ Target Submission Readiness ----\n# These fields are all required for submitting a FINZ target.\n# Missing fields are flagged but DO NOT block the assessment.\n\nfinz_submission_cols = {\n    'company_name':       'Entity/Project/Asset Name',\n    'isin':               'ISIN',\n    'lei':                'LEI',\n    'asset_class':        'Asset Class',\n    'sector':             'Sector',\n    'financial_activity': 'Financial Activity',\n    'segment':            'Segment (A/B/C/D)',\n    'investment_value':   'Investment Value',\n}\n\nprint(f\"\\n{'=' * 70}\")\nprint(\"  FINZ TARGET SUBMISSION READINESS\")\nprint(\"  (All fields below are required to submit a FINZ target)\")\nprint(f\"{'=' * 70}\")\n\nsubmission_ready = True\nmissing_cols = []\nincomplete_cols = []\n\nfor col, label in finz_submission_cols.items():\n    if col not in df_portfolio.columns:\n        missing_cols.append(label)\n        submission_ready = False\n    else:\n        populated = df_portfolio[col].notna().sum()\n        total = len(df_portfolio)\n        if populated < total:\n            incomplete_cols.append((label, populated, total))\n            submission_ready = False\n\nif missing_cols:\n    print(f\"\\n  MISSING COLUMNS (not in input file):\")\n    for label in missing_cols:\n        print(f\"    - {label}\")\n\nif incomplete_cols:\n    print(f\"\\n  INCOMPLETE COLUMNS (some rows have blank values):\")\n    for label, populated, total in incomplete_cols:\n        print(f\"    - {label}: {populated}/{total} populated ({total - populated} missing)\")\n\nif submission_ready:\n    print(f\"\\n  SUBMISSION READY: All required fields are present and complete.\")\nelse:\n    print(f\"\\n  NOT YET SUBMISSION READY: The fields above must be completed\")\n    print(f\"  before this assessment can be submitted as a FINZ target.\")\n    print(f\"  The CTA lookup and assessment will still run with available data.\")\n\n\n# ---- 3. Field-Specific Validation ----\n\n# Validate segment values if present\nif 'segment' in df_portfolio.columns:\n    valid_segments = {'A', 'B', 'C', 'D'}\n    segment_values = df_portfolio['segment'].dropna().unique()\n    invalid_segments = [s for s in segment_values if str(s).upper() not in valid_segments]\n    if invalid_segments:\n        print(f\"\\n  WARNING: Invalid segment values: {invalid_segments}. Expected A/B/C/D.\")\n    elif len(segment_values) > 0:\n        print(f\"\\n  Segment values validated: {sorted(segment_values)}\")\n\n# Validate financial activity values if present\nif 'financial_activity' in df_portfolio.columns:\n    valid_activities = {\n        'Lending', 'Asset Owner Investing', 'Asset Manager Investing',\n        'Re/insurance underwriting', 'Capital Markets'\n    }\n    activity_values = df_portfolio['financial_activity'].dropna().unique()\n    unknown_activities = [a for a in activity_values if a not in valid_activities]\n    if unknown_activities:\n        print(f\"\\n  NOTE: Non-standard financial activity values: {unknown_activities}\")\n        print(f\"  Expected: {sorted(valid_activities)}\")\n\n\n# ---- 4. Override Fields ----\noverride_cols = {\n    'methodology_used': 'Methodology (user override)',\n    'methodology_version': 'Methodology Version (user override)',\n    'data_source': 'Data Source (user override)',\n    'finz_status': 'FINZ Status (user override)',\n}\n\noverride_found = False\nfor col, label in override_cols.items():\n    if col in df_portfolio.columns:\n        non_null = df_portfolio[col].notna().sum()\n        if non_null > 0:\n            if not override_found:\n                print(f\"\\n  User override fields detected:\")\n                override_found = True\n            print(f\"    {label}: {non_null}/{len(df_portfolio)} pre-populated\")\n\nif not override_found:\n    print(f\"\\n  No user override fields detected. All assessment fields will be auto-populated.\")\n\nprint(f\"\\n{'=' * 70}\")\nprint(f\"  Proceeding with {len(df_portfolio)} entities\")\nprint(f\"{'=' * 70}\")"
  },
  {
   "cell_type": "markdown",
   "id": "analysis_date_md",
   "metadata": {},
   "source": [
    "## USER INPUT: Select Analysis Date\n",
    "\n",
    "Choose the date for your analysis. This determines which SBTi targets are included (only targets published by this date).\n",
    "\n",
    "**Default:** December 31, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis_date_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2025   # enter the year for which you want to run the assessment\n",
    "month = 12    # enter the month\n",
    "day = 31      # enter the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "set_date",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_date = datetime(year, month, day)\n",
    "print(f\"Analysis date set to: {user_date.strftime('%B %d, %Y')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbti_db_md",
   "metadata": {},
   "source": [
    "## Loading SBTi Database\n",
    "\n",
    "The tool automatically downloads the latest list of companies with validated Science Based Targets from the SBTi Companies Taking Action (CTA) database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_sbti_db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SBTi Companies Taking Action database\n",
    "from SBTi.data.sbti import SBTi\n",
    "\n",
    "print(\"Loading SBTi database (this may take a moment)...\")\n",
    "sbti_provider = SBTi()\n",
    "cta_file = sbti_provider.targets.copy()\n",
    "\n",
    "# Count unique companies with targets\n",
    "companies_with_targets_count = len(\n",
    "    cta_file[cta_file[sbti_provider.c.COL_ACTION] == sbti_provider.c.VALUE_ACTION_TARGET][\n",
    "        sbti_provider.c.COL_COMPANY_NAME\n",
    "    ].unique()\n",
    ")\n",
    "print(f\"Loaded SBTi database: {companies_with_targets_count:,} companies with validated targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter_sbti_date",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FILTER SBTi DATA BY ANALYSIS DATE\n",
    "# =============================================================================\n",
    "\n",
    "targets = cta_file.copy()\n",
    "companies_with_targets = targets[\n",
    "    targets[sbti_provider.c.COL_ACTION] == sbti_provider.c.VALUE_ACTION_TARGET\n",
    "]\n",
    "\n",
    "# Handle date column format variations\n",
    "date_col = sbti_provider.c.COL_DATE_PUBLISHED\n",
    "potential_date_cols = ['date_updated', 'Date Updated', 'date_published', 'Date Published']\n",
    "\n",
    "if date_col not in companies_with_targets.columns:\n",
    "    found_date_col = next(\n",
    "        (col for col in potential_date_cols if col in companies_with_targets.columns), None\n",
    "    )\n",
    "    if found_date_col:\n",
    "        companies_with_targets = companies_with_targets.rename(columns={found_date_col: date_col})\n",
    "        print(f\"Date column mapped: '{found_date_col}' -> '{date_col}'\")\n",
    "    else:\n",
    "        print(f\"WARNING: No date column found. Date filtering will be skipped.\")\n",
    "else:\n",
    "    print(f\"Date column: '{date_col}'\")\n",
    "\n",
    "# Apply date filter\n",
    "df_targets = companies_with_targets.copy()\n",
    "if date_col in df_targets.columns:\n",
    "    df_targets[date_col] = pd.to_datetime(df_targets[date_col], errors='coerce')\n",
    "    date_filtered_df = df_targets.loc[df_targets[date_col] <= user_date]\n",
    "else:\n",
    "    date_filtered_df = df_targets\n",
    "\n",
    "# Name normalization function\n",
    "def normalize_name(name):\n",
    "    \"\"\"Normalize company name for matching: lowercase, collapse whitespace.\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "    return ' '.join(str(name).lower().split())\n",
    "\n",
    "# Create lookup sets for matching\n",
    "date_filtered_df = date_filtered_df.copy()\n",
    "date_filtered_df['company_name_normalized'] = date_filtered_df[\n",
    "    sbti_provider.c.COL_COMPANY_NAME\n",
    "].apply(normalize_name)\n",
    "\n",
    "company_name_set = set(date_filtered_df['company_name_normalized'].dropna())\n",
    "isin_set = set(date_filtered_df[sbti_provider.c.COL_COMPANY_ISIN].dropna())\n",
    "lei_set = set(date_filtered_df[sbti_provider.c.COL_COMPANY_LEI].dropna())\n",
    "\n",
    "print(f\"\\nFiltered to targets published by {user_date.strftime('%B %d, %Y')}\")\n",
    "print(f\"  - Companies for name matching: {len(company_name_set):,}\")\n",
    "print(f\"  - Unique ISINs: {len(isin_set):,}\")\n",
    "print(f\"  - Unique LEIs: {len(lei_set):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auto_populate_md",
   "metadata": {},
   "source": [
    "## Auto-Populate FINZ Fields\n",
    "\n",
    "The notebook now looks up each portfolio entity in the SBTi CTA database and auto-populates:\n",
    "- **Methodology used** (default: \"SBTi Target Status\")\n",
    "- **Assessed metric** (target classification: 1.5°C, WB2°C, 2°C, etc.)\n",
    "- **Methodology version** (SBTi CTA file date)\n",
    "- **Data source** (\"SBTi Companies Taking Action Database\")\n",
    "- **FINZ status** (In Transition / Assessed / Not Aligned)\n",
    "\n",
    "Any values you provided in the input file are **preserved as overrides**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auto_populate_finz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AUTO-POPULATE FINZ FIELDS FROM SBTi CTA DATABASE\n",
    "# =============================================================================\n",
    "\n",
    "# Detect target classification column in CTA data\n",
    "TARGET_CLASSIFICATION_COL = None\n",
    "potential_tc_cols = [\n",
    "    'Target Classification', 'target_classification',\n",
    "    'Near Term Classification', 'near_term_target_classification',\n",
    "    'target_classification_short'\n",
    "]\n",
    "for col in potential_tc_cols:\n",
    "    if col in date_filtered_df.columns:\n",
    "        TARGET_CLASSIFICATION_COL = col\n",
    "        break\n",
    "\n",
    "if TARGET_CLASSIFICATION_COL:\n",
    "    print(f\"Target Classification column: '{TARGET_CLASSIFICATION_COL}'\")\n",
    "    unique_classifications = date_filtered_df[TARGET_CLASSIFICATION_COL].dropna().unique()\n",
    "    print(f\"Classifications found: {sorted([str(x) for x in unique_classifications])}\")\n",
    "else:\n",
    "    print(\"WARNING: No Target Classification column found in CTA data.\")\n",
    "    print(\"FINZ status will be based on SBTi validation status only.\")\n",
    "\n",
    "# CTA file date for methodology_version\n",
    "cta_file_date = user_date.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# --- Matching and lookup functions ---\n",
    "\n",
    "def match_entity(row):\n",
    "    \"\"\"\n",
    "    Match a portfolio entity against the SBTi CTA database.\n",
    "    Returns (match_method, target_classification) or (None, None).\n",
    "    \n",
    "    Priority: LEI > ISIN > Company Name\n",
    "    \"\"\"\n",
    "    # LEI match (most reliable)\n",
    "    if 'lei' in row.index and pd.notna(row.get('lei')):\n",
    "        lei_val = str(row['lei']).strip()\n",
    "        if lei_val and lei_val.lower() != 'nan' and len(lei_val) > 3:\n",
    "            if lei_val in lei_set:\n",
    "                classification = _lookup_classification_by_field(\n",
    "                    sbti_provider.c.COL_COMPANY_LEI, lei_val\n",
    "                )\n",
    "                return 'LEI', classification\n",
    "    \n",
    "    # ISIN match\n",
    "    if 'isin' in row.index and pd.notna(row.get('isin')):\n",
    "        isin_val = str(row['isin']).strip()\n",
    "        if isin_val and isin_val.lower() != 'nan':\n",
    "            if isin_val in isin_set:\n",
    "                classification = _lookup_classification_by_field(\n",
    "                    sbti_provider.c.COL_COMPANY_ISIN, isin_val\n",
    "                )\n",
    "                return 'ISIN', classification\n",
    "    \n",
    "    # Company name match (fallback)\n",
    "    if 'company_name' in row.index and pd.notna(row.get('company_name')):\n",
    "        normalized = normalize_name(row['company_name'])\n",
    "        if normalized and normalized in company_name_set:\n",
    "            classification = _lookup_classification_by_name(normalized)\n",
    "            return 'Name', classification\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _lookup_classification_by_field(col_name, value):\n",
    "    \"\"\"Look up target classification by a specific CTA column.\"\"\"\n",
    "    if TARGET_CLASSIFICATION_COL is None:\n",
    "        return None\n",
    "    matches = date_filtered_df[date_filtered_df[col_name] == value]\n",
    "    if len(matches) > 0:\n",
    "        classification = matches.iloc[0][TARGET_CLASSIFICATION_COL]\n",
    "        if pd.notna(classification):\n",
    "            return str(classification)\n",
    "    return None\n",
    "\n",
    "\n",
    "def _lookup_classification_by_name(normalized_name):\n",
    "    \"\"\"Look up target classification by normalized company name.\"\"\"\n",
    "    if TARGET_CLASSIFICATION_COL is None:\n",
    "        return None\n",
    "    matches = date_filtered_df[\n",
    "        date_filtered_df['company_name_normalized'] == normalized_name\n",
    "    ]\n",
    "    if len(matches) > 0:\n",
    "        classification = matches.iloc[0][TARGET_CLASSIFICATION_COL]\n",
    "        if pd.notna(classification):\n",
    "            return str(classification)\n",
    "    return None\n",
    "\n",
    "\n",
    "def derive_finz_status(classification, matched):\n",
    "    \"\"\"\n",
    "    Derive FINZ status from target classification.\n",
    "    \n",
    "    - In Transition: pure 1.5C target\n",
    "    - Assessed: has SBTi target but not 1.5C\n",
    "    - Not Aligned: no SBTi target found\n",
    "    \"\"\"\n",
    "    if not matched:\n",
    "        return 'Not Aligned'\n",
    "    \n",
    "    if classification:\n",
    "        pure_15c = ['1.5°C', '1.5°C/1.5°C', '1.5']\n",
    "        if any(val in classification for val in pure_15c):\n",
    "            return 'In Transition'\n",
    "    \n",
    "    return 'Assessed'\n",
    "\n",
    "\n",
    "# --- Apply matching and auto-population ---\n",
    "\n",
    "match_methods = []\n",
    "classifications = []\n",
    "\n",
    "for idx, row in df_portfolio.iterrows():\n",
    "    method, classification = match_entity(row)\n",
    "    match_methods.append(method)\n",
    "    classifications.append(classification)\n",
    "\n",
    "df_portfolio['_match_method'] = match_methods\n",
    "df_portfolio['_auto_classification'] = classifications\n",
    "df_portfolio['_matched'] = df_portfolio['_match_method'].notna()\n",
    "\n",
    "\n",
    "# --- Auto-populate fields (respecting user overrides) ---\n",
    "\n",
    "def auto_fill(df, col_name, auto_value_func):\n",
    "    \"\"\"\n",
    "    Auto-fill a column: preserve user-provided values, fill blanks with auto value.\n",
    "    Returns count of (auto_filled, user_overrides).\n",
    "    \"\"\"\n",
    "    if col_name not in df.columns:\n",
    "        df[col_name] = None\n",
    "    \n",
    "    user_provided = df[col_name].notna()\n",
    "    user_count = user_provided.sum()\n",
    "    \n",
    "    # Fill blanks with auto values\n",
    "    for idx in df.index:\n",
    "        if pd.isna(df.at[idx, col_name]) or str(df.at[idx, col_name]).strip() == '':\n",
    "            df.at[idx, col_name] = auto_value_func(df.loc[idx])\n",
    "    \n",
    "    auto_count = len(df) - user_count\n",
    "    return auto_count, int(user_count)\n",
    "\n",
    "\n",
    "# methodology_used\n",
    "auto_meth, override_meth = auto_fill(\n",
    "    df_portfolio, 'methodology_used',\n",
    "    lambda row: 'SBTi Target Status'\n",
    ")\n",
    "\n",
    "# assessed_metric\n",
    "auto_metric, override_metric = auto_fill(\n",
    "    df_portfolio, 'assessed_metric',\n",
    "    lambda row: row['_auto_classification'] if pd.notna(row.get('_auto_classification')) else 'No SBTi Target'\n",
    ")\n",
    "\n",
    "# methodology_version\n",
    "auto_ver, override_ver = auto_fill(\n",
    "    df_portfolio, 'methodology_version',\n",
    "    lambda row: f\"SBTi CTA {cta_file_date}\"\n",
    ")\n",
    "\n",
    "# data_source\n",
    "auto_src, override_src = auto_fill(\n",
    "    df_portfolio, 'data_source',\n",
    "    lambda row: 'SBTi Companies Taking Action Database'\n",
    ")\n",
    "\n",
    "# finz_status (special: also check for user override like 'Climate Solution')\n",
    "auto_status, override_status = auto_fill(\n",
    "    df_portfolio, 'finz_status',\n",
    "    lambda row: derive_finz_status(row.get('_auto_classification'), row.get('_matched', False))\n",
    ")\n",
    "\n",
    "\n",
    "# --- Report results ---\n",
    "\n",
    "total = len(df_portfolio)\n",
    "matched = df_portfolio['_matched'].sum()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  FINZ FIELD AUTO-POPULATION RESULTS\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "print(f\"\\nSBTi CTA Matching: {matched}/{total} entities matched\")\n",
    "match_counts = df_portfolio['_match_method'].value_counts()\n",
    "for method in ['LEI', 'ISIN', 'Name']:\n",
    "    count = match_counts.get(method, 0)\n",
    "    if count > 0:\n",
    "        print(f\"  - {method}: {count}\")\n",
    "\n",
    "print(f\"\\nField population (auto-filled / user-override):\")\n",
    "print(f\"  - methodology_used:    {auto_meth} auto / {override_meth} user\")\n",
    "print(f\"  - assessed_metric:     {auto_metric} auto / {override_metric} user\")\n",
    "print(f\"  - methodology_version: {auto_ver} auto / {override_ver} user\")\n",
    "print(f\"  - data_source:         {auto_src} auto / {override_src} user\")\n",
    "print(f\"  - finz_status:         {auto_status} auto / {override_status} user\")\n",
    "\n",
    "print(f\"\\nFINZ Status distribution:\")\n",
    "status_counts = df_portfolio['finz_status'].value_counts()\n",
    "for status, count in status_counts.items():\n",
    "    print(f\"  - {status}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results_table_md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Your Results: FINZ Alignment Assessment\n",
    "\n",
    "## Per-Entity Assessment\n",
    "\n",
    "The table below shows the full FINZ alignment assessment for each entity in your portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PER-ENTITY ASSESSMENT TABLE\n",
    "# =============================================================================\n",
    "\n",
    "# Select display columns (exclude internal working columns)\n",
    "display_cols = []\n",
    "\n",
    "# Identifiers\n",
    "for col in ['company_name', 'isin', 'lei']:\n",
    "    if col in df_portfolio.columns:\n",
    "        display_cols.append(col)\n",
    "\n",
    "# Portfolio context\n",
    "for col in ['asset_class', 'sector', 'financial_activity', 'segment', 'investment_value']:\n",
    "    if col in df_portfolio.columns:\n",
    "        display_cols.append(col)\n",
    "\n",
    "# FINZ assessment fields\n",
    "finz_cols = ['methodology_used', 'assessed_metric', 'methodology_version', 'data_source', 'finz_status']\n",
    "display_cols.extend([c for c in finz_cols if c in df_portfolio.columns])\n",
    "\n",
    "# Match method for transparency\n",
    "display_cols.append('_match_method')\n",
    "\n",
    "df_display = df_portfolio[display_cols].copy()\n",
    "df_display = df_display.rename(columns={'_match_method': 'match_method'})\n",
    "\n",
    "print(f\"FINZ Alignment Assessment: {len(df_display)} entities\")\n",
    "print()\n",
    "df_display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_activity_md",
   "metadata": {},
   "source": [
    "## Summary by Financial Activity\n",
    "\n",
    "Coverage metrics grouped by financial activity type, with segment (A/B/C/D) breakdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_by_activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY BY FINANCIAL ACTIVITY\n",
    "# =============================================================================\n",
    "\n",
    "has_financial_activity = 'financial_activity' in df_portfolio.columns\n",
    "has_investment_value = 'investment_value' in df_portfolio.columns\n",
    "has_segment = 'segment' in df_portfolio.columns\n",
    "\n",
    "if has_financial_activity:\n",
    "    activities = df_portfolio['financial_activity'].dropna().unique()\n",
    "    \n",
    "    print(\"=\" * 90)\n",
    "    print(\"  FINZ ALIGNMENT ASSESSMENT — SUMMARY BY FINANCIAL ACTIVITY\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    for activity in sorted(activities):\n",
    "        df_activity = df_portfolio[df_portfolio['financial_activity'] == activity]\n",
    "        activity_count = len(df_activity)\n",
    "        activity_value = df_activity['investment_value'].sum() if has_investment_value else 0\n",
    "        \n",
    "        print(f\"\\n{'─' * 90}\")\n",
    "        print(f\"  {activity.upper()}\")\n",
    "        print(f\"{'─' * 90}\")\n",
    "        print(f\"  Entities: {activity_count}\")\n",
    "        if has_investment_value:\n",
    "            print(f\"  Total Value: ${activity_value:,.0f}\")\n",
    "        \n",
    "        # Segment breakdown\n",
    "        if has_segment:\n",
    "            segment_counts = df_activity['segment'].value_counts().sort_index()\n",
    "            segment_str = ', '.join([f\"{seg}: {cnt}\" for seg, cnt in segment_counts.items()])\n",
    "            print(f\"  Segments: {segment_str}\")\n",
    "        \n",
    "        # FINZ status breakdown\n",
    "        print(f\"\\n  {'FINZ Status':<20} {'# Entities':>12} {'% Entities':>12}\", end='')\n",
    "        if has_investment_value:\n",
    "            print(f\" {'$ Value':>15} {'$ %':>10}\", end='')\n",
    "        print()\n",
    "        print(f\"  {'─' * 70}\")\n",
    "        \n",
    "        for status in ['In Transition', 'Assessed', 'Not Aligned', 'Climate Solution']:\n",
    "            status_mask = df_activity['finz_status'] == status\n",
    "            status_count = status_mask.sum()\n",
    "            if status_count == 0:\n",
    "                continue\n",
    "            status_pct = (status_count / activity_count * 100) if activity_count > 0 else 0\n",
    "            \n",
    "            print(f\"  {status:<20} {status_count:>12} {status_pct:>11.1f}%\", end='')\n",
    "            if has_investment_value:\n",
    "                status_value = df_activity.loc[status_mask, 'investment_value'].sum()\n",
    "                status_value_pct = (status_value / activity_value * 100) if activity_value > 0 else 0\n",
    "                print(f\" ${status_value:>13,.0f} {status_value_pct:>9.1f}%\", end='')\n",
    "            print()\n",
    "    \n",
    "    # Overall totals\n",
    "    total_count = len(df_portfolio)\n",
    "    total_value = df_portfolio['investment_value'].sum() if has_investment_value else 0\n",
    "    \n",
    "    print(f\"\\n{'=' * 90}\")\n",
    "    print(f\"  OVERALL PORTFOLIO TOTALS\")\n",
    "    print(f\"{'=' * 90}\")\n",
    "    print(f\"  Total Entities: {total_count}\")\n",
    "    if has_investment_value:\n",
    "        print(f\"  Total Value: ${total_value:,.0f}\")\n",
    "    \n",
    "    print(f\"\\n  {'FINZ Status':<20} {'# Entities':>12} {'% Entities':>12}\", end='')\n",
    "    if has_investment_value:\n",
    "        print(f\" {'$ Value':>15} {'$ %':>10}\", end='')\n",
    "    print()\n",
    "    print(f\"  {'─' * 70}\")\n",
    "    \n",
    "    for status in ['In Transition', 'Assessed', 'Not Aligned', 'Climate Solution']:\n",
    "        status_mask = df_portfolio['finz_status'] == status\n",
    "        status_count = status_mask.sum()\n",
    "        if status_count == 0:\n",
    "            continue\n",
    "        status_pct = (status_count / total_count * 100) if total_count > 0 else 0\n",
    "        \n",
    "        print(f\"  {status:<20} {status_count:>12} {status_pct:>11.1f}%\", end='')\n",
    "        if has_investment_value:\n",
    "            status_value = df_portfolio.loc[status_mask, 'investment_value'].sum()\n",
    "            status_value_pct = (status_value / total_value * 100) if total_value > 0 else 0\n",
    "            print(f\" ${status_value:>13,.0f} {status_value_pct:>9.1f}%\", end='')\n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"No 'financial_activity' column found. Showing overall summary only.\")\n",
    "    print(f\"\\nFINZ Status Distribution:\")\n",
    "    print(df_portfolio['finz_status'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualizations_md",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualizations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATIONS\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Color mapping for FINZ statuses\n",
    "finz_colors = {\n",
    "    'In Transition': '#2ecc71',    # Green\n",
    "    'Assessed': '#f39c12',          # Orange\n",
    "    'Not Aligned': '#e74c3c',       # Red\n",
    "    'Climate Solution': '#3498db',  # Blue\n",
    "}\n",
    "\n",
    "finz_status_order = ['In Transition', 'Assessed', 'Not Aligned', 'Climate Solution']\n",
    "present_statuses = [s for s in finz_status_order if s in df_portfolio['finz_status'].values]\n",
    "\n",
    "has_financial_activity = 'financial_activity' in df_portfolio.columns\n",
    "has_investment_value = 'investment_value' in df_portfolio.columns\n",
    "has_segment = 'segment' in df_portfolio.columns\n",
    "\n",
    "# Determine layout based on available data\n",
    "n_charts = 2 + (1 if has_financial_activity else 0) + (1 if has_segment and has_financial_activity else 0)\n",
    "\n",
    "if has_financial_activity:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('FINZ Alignment Assessment', fontsize=18, fontweight='bold', y=1.02)\n",
    "    ax_pie = axes[0, 0]\n",
    "    ax_bar_overall = axes[0, 1]\n",
    "    ax_stacked = axes[1, 0]\n",
    "    ax_segment = axes[1, 1]\n",
    "else:\n",
    "    fig, (ax_pie, ax_bar_overall) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle('FINZ Alignment Assessment', fontsize=18, fontweight='bold', y=1.02)\n",
    "\n",
    "# --- Chart 1: Pie chart - overall FINZ status ---\n",
    "if has_investment_value:\n",
    "    pie_values = [df_portfolio.loc[df_portfolio['finz_status'] == s, 'investment_value'].sum() for s in present_statuses]\n",
    "    pie_title = 'Overall FINZ Status by Investment Value ($)'\n",
    "else:\n",
    "    pie_values = [len(df_portfolio[df_portfolio['finz_status'] == s]) for s in present_statuses]\n",
    "    pie_title = 'Overall FINZ Status by Entity Count (#)'\n",
    "\n",
    "pie_colors = [finz_colors[s] for s in present_statuses]\n",
    "wedges, texts, autotexts = ax_pie.pie(\n",
    "    pie_values, labels=present_statuses,\n",
    "    autopct=lambda pct: f'{pct:.1f}%' if pct > 0 else '',\n",
    "    colors=pie_colors, startangle=90\n",
    ")\n",
    "ax_pie.set_title(pie_title, fontsize=13, fontweight='bold')\n",
    "\n",
    "# --- Chart 2: Bar chart - entity count by status ---\n",
    "count_values = [len(df_portfolio[df_portfolio['finz_status'] == s]) for s in present_statuses]\n",
    "bars = ax_bar_overall.bar(present_statuses, count_values, color=[finz_colors[s] for s in present_statuses])\n",
    "ax_bar_overall.set_ylabel('Number of Entities')\n",
    "ax_bar_overall.set_title('Overall FINZ Status by Entity Count', fontsize=13, fontweight='bold')\n",
    "for bar, count in zip(bars, count_values):\n",
    "    ax_bar_overall.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
    "                        str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "if has_financial_activity:\n",
    "    # --- Chart 3: Stacked bar - FINZ status by financial activity ---\n",
    "    activities = sorted(df_portfolio['financial_activity'].dropna().unique())\n",
    "    \n",
    "    bottom = np.zeros(len(activities))\n",
    "    for status in present_statuses:\n",
    "        values = []\n",
    "        for activity in activities:\n",
    "            mask = (df_portfolio['financial_activity'] == activity) & (df_portfolio['finz_status'] == status)\n",
    "            values.append(mask.sum())\n",
    "        ax_stacked.bar(activities, values, bottom=bottom, label=status, color=finz_colors[status])\n",
    "        bottom += values\n",
    "    \n",
    "    ax_stacked.set_ylabel('Number of Entities')\n",
    "    ax_stacked.set_title('FINZ Status by Financial Activity', fontsize=13, fontweight='bold')\n",
    "    ax_stacked.legend(loc='upper right', fontsize=9)\n",
    "    ax_stacked.tick_params(axis='x', rotation=25)\n",
    "    \n",
    "    # --- Chart 4: Segment distribution by financial activity ---\n",
    "    if has_segment:\n",
    "        segment_order = ['A', 'B', 'C', 'D']\n",
    "        present_segments = [s for s in segment_order if s in df_portfolio['segment'].values]\n",
    "        segment_colors = {'A': '#2c3e50', 'B': '#7f8c8d', 'C': '#bdc3c7', 'D': '#ecf0f1'}\n",
    "        \n",
    "        bottom = np.zeros(len(activities))\n",
    "        for seg in present_segments:\n",
    "            values = []\n",
    "            for activity in activities:\n",
    "                mask = (df_portfolio['financial_activity'] == activity) & (df_portfolio['segment'] == seg)\n",
    "                values.append(mask.sum())\n",
    "            ax_segment.bar(activities, values, bottom=bottom, label=f'Segment {seg}', color=segment_colors[seg])\n",
    "            bottom += values\n",
    "        \n",
    "        ax_segment.set_ylabel('Number of Entities')\n",
    "        ax_segment.set_title('Segment Distribution by Financial Activity', fontsize=13, fontweight='bold')\n",
    "        ax_segment.legend(loc='upper right', fontsize=9)\n",
    "        ax_segment.tick_params(axis='x', rotation=25)\n",
    "    else:\n",
    "        ax_segment.text(0.5, 0.5, 'No segment data\\nprovided',\n",
    "                        ha='center', va='center', fontsize=14, color='gray',\n",
    "                        transform=ax_segment.transAxes)\n",
    "        ax_segment.set_title('Segment Distribution', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export_md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Download Your Results\n",
    "\n",
    "Run the cell below to save your results as an Excel file.\n",
    "\n",
    "## Output File\n",
    "**Filename:** `finz_alignment_assessment.xlsx`  \n",
    "**Location:** `data/` folder\n",
    "\n",
    "## What's Included\n",
    "\n",
    "| Sheet | Contents |\n",
    "|-------|----------|\n",
    "| **Assessment** | Full per-entity data with all FINZ fields (identifiers, asset class, sector, financial activity, segment, methodology, assessed metric, FINZ status) |\n",
    "| **Summary by Activity** | Coverage metrics grouped by financial activity with segment and FINZ status breakdown |\n",
    "| **Overall Summary** | Portfolio-level metrics, methodology notes, and metadata |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_excel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE RESULTS TO EXCEL\n",
    "# =============================================================================\n",
    "\n",
    "output_filename = 'finz_alignment_assessment'\n",
    "output_dir = 'data'\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# --- Sheet 1: Assessment (per-entity) ---\n",
    "export_cols = []\n",
    "for col in ['company_name', 'isin', 'lei', 'asset_class', 'sector',\n",
    "            'financial_activity', 'segment', 'investment_value',\n",
    "            'methodology_used', 'assessed_metric', 'methodology_version',\n",
    "            'data_source', 'finz_status', '_match_method']:\n",
    "    if col in df_portfolio.columns:\n",
    "        export_cols.append(col)\n",
    "\n",
    "df_export = df_portfolio[export_cols].copy()\n",
    "df_export = df_export.rename(columns={'_match_method': 'match_method'})\n",
    "\n",
    "\n",
    "# --- Sheet 2: Summary by Activity ---\n",
    "summary_rows = []\n",
    "\n",
    "has_financial_activity = 'financial_activity' in df_portfolio.columns\n",
    "has_investment_value = 'investment_value' in df_portfolio.columns\n",
    "has_segment = 'segment' in df_portfolio.columns\n",
    "\n",
    "if has_financial_activity:\n",
    "    for activity in sorted(df_portfolio['financial_activity'].dropna().unique()):\n",
    "        df_act = df_portfolio[df_portfolio['financial_activity'] == activity]\n",
    "        act_count = len(df_act)\n",
    "        act_value = df_act['investment_value'].sum() if has_investment_value else 0\n",
    "        \n",
    "        for status in ['In Transition', 'Assessed', 'Not Aligned', 'Climate Solution']:\n",
    "            mask = df_act['finz_status'] == status\n",
    "            s_count = mask.sum()\n",
    "            if s_count == 0:\n",
    "                continue\n",
    "            s_value = df_act.loc[mask, 'investment_value'].sum() if has_investment_value else 0\n",
    "            \n",
    "            # Segment breakdown within this activity+status\n",
    "            seg_str = ''\n",
    "            if has_segment:\n",
    "                seg_counts = df_act.loc[mask, 'segment'].value_counts().sort_index()\n",
    "                seg_str = ', '.join([f\"{seg}: {cnt}\" for seg, cnt in seg_counts.items()])\n",
    "            \n",
    "            summary_rows.append({\n",
    "                'Financial Activity': activity,\n",
    "                'FINZ Status': status,\n",
    "                '# Entities': s_count,\n",
    "                '% Entities': f\"{s_count / act_count * 100:.1f}%\" if act_count > 0 else '0.0%',\n",
    "                '$ Value': s_value if has_investment_value else '',\n",
    "                '$ %': f\"{s_value / act_value * 100:.1f}%\" if act_value > 0 and has_investment_value else '',\n",
    "                'Segment Breakdown': seg_str,\n",
    "            })\n",
    "\n",
    "df_summary_activity = pd.DataFrame(summary_rows) if summary_rows else pd.DataFrame()\n",
    "\n",
    "\n",
    "# --- Sheet 3: Overall Summary ---\n",
    "total_count = len(df_portfolio)\n",
    "total_value = df_portfolio['investment_value'].sum() if has_investment_value else 0\n",
    "matched_count = df_portfolio['_matched'].sum()\n",
    "\n",
    "# FINZ status totals\n",
    "in_transition_count = (df_portfolio['finz_status'] == 'In Transition').sum()\n",
    "assessed_count = (df_portfolio['finz_status'] == 'Assessed').sum()\n",
    "not_aligned_count = (df_portfolio['finz_status'] == 'Not Aligned').sum()\n",
    "climate_solution_count = (df_portfolio['finz_status'] == 'Climate Solution').sum()\n",
    "\n",
    "in_transition_value = df_portfolio.loc[df_portfolio['finz_status'] == 'In Transition', 'investment_value'].sum() if has_investment_value else 0\n",
    "assessed_value = df_portfolio.loc[df_portfolio['finz_status'] == 'Assessed', 'investment_value'].sum() if has_investment_value else 0\n",
    "not_aligned_value = df_portfolio.loc[df_portfolio['finz_status'] == 'Not Aligned', 'investment_value'].sum() if has_investment_value else 0\n",
    "climate_solution_value = df_portfolio.loc[df_portfolio['finz_status'] == 'Climate Solution', 'investment_value'].sum() if has_investment_value else 0\n",
    "\n",
    "overall_data = {\n",
    "    'Metric': [\n",
    "        'FINZ ALIGNMENT ASSESSMENT', '', '',\n",
    "        'Analysis Date', 'Assessment Date', 'Default Methodology', 'Default Data Source', '',\n",
    "        'PORTFOLIO TOTALS', '  Total Entities', '  Total Investment Value',\n",
    "        '  Entities Matched in SBTi CTA', '',\n",
    "        'FINZ STATUS BREAKDOWN', '',\n",
    "        '  In Transition', '    # Entities', '    $ Value',\n",
    "        '  Assessed', '    # Entities', '    $ Value',\n",
    "        '  Not Aligned', '    # Entities', '    $ Value',\n",
    "        '  Climate Solution', '    # Entities', '    $ Value',\n",
    "    ],\n",
    "    'Value': [\n",
    "        'Entity-Level Climate Alignment', '', '',\n",
    "        datetime.now().strftime('%Y-%m-%d'), user_date.strftime('%Y-%m-%d'),\n",
    "        'SBTi Target Status', 'SBTi Companies Taking Action Database', '',\n",
    "        '', str(total_count),\n",
    "        f\"${total_value:,.0f}\" if has_investment_value else 'N/A',\n",
    "        f\"{int(matched_count)}/{total_count}\", '',\n",
    "        '', '',\n",
    "        '', str(in_transition_count),\n",
    "        f\"${in_transition_value:,.0f}\" if has_investment_value else 'N/A',\n",
    "        '', str(assessed_count),\n",
    "        f\"${assessed_value:,.0f}\" if has_investment_value else 'N/A',\n",
    "        '', str(not_aligned_count),\n",
    "        f\"${not_aligned_value:,.0f}\" if has_investment_value else 'N/A',\n",
    "        '', str(climate_solution_count),\n",
    "        f\"${climate_solution_value:,.0f}\" if has_investment_value else 'N/A',\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_overall = pd.DataFrame(overall_data)\n",
    "\n",
    "\n",
    "# --- Write Excel ---\n",
    "excel_path = f\"{output_dir}/{output_filename}.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "    df_export.to_excel(writer, sheet_name='Assessment', index=False)\n",
    "    if not df_summary_activity.empty:\n",
    "        df_summary_activity.to_excel(writer, sheet_name='Summary by Activity', index=False)\n",
    "    df_overall.to_excel(writer, sheet_name='Overall Summary', index=False)\n",
    "\n",
    "abs_path = os.path.abspath(excel_path)\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"     FINZ ALIGNMENT ASSESSMENT — SAVED\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"\\nFile saved to: {excel_path}\")\n",
    "print(f\"\\nContents:\")\n",
    "print(f\"  - Assessment sheet: Per-entity FINZ alignment data\")\n",
    "print(f\"  - Summary by Activity sheet: Coverage by financial activity + segment\")\n",
    "print(f\"  - Overall Summary sheet: Portfolio-level metrics\")\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(f\"\\n[Google Colab] To download your file:\")\n",
    "    print(f\"   1. Click the folder icon in the left sidebar\")\n",
    "    print(f\"   2. Navigate to 'data' folder\")\n",
    "    print(f\"   3. Right-click '{output_filename}.xlsx' > Download\")\n",
    "else:\n",
    "    print(f\"\\n[Local] Full path: {abs_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "\n",
    "# Preview\n",
    "print(f\"\\nPreview of exported assessment data:\")\n",
    "print(df_export.head(10).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}