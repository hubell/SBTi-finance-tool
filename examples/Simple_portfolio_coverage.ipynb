{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7848b6",
   "metadata": {},
   "source": "# SBTi-Finance Tool - FINZ Portfolio Coverage Calculator\n\nThis notebook calculates **FINZ climate alignment coverage** â€” the percentage of your investment portfolio that holds companies with validated 1.5Â°C Science Based Targets.\n\n**FINZ Climate Alignment Assessment:**\n- **In Transition**: Companies with validated 1.5Â°C SBTi targets\n- **Assessed**: All other companies (including WB2Â°C, 2Â°C, or no target)\n\n**Coverage is measured two ways (no weighting, simple per-entity basis):**\n1. **By Investment Value ($)** â€” $ covered / total $ portfolio value\n2. **By Company Count (#)** â€” # companies / total # companies\n\nThe granular **target classification** (1.5Â°C, WB2Â°C, 2Â°C, etc.) is preserved in the output for detailed analysis."
  },
  {
   "cell_type": "markdown",
   "id": "intro_guide",
   "metadata": {},
   "source": "# Quick Start Guide\n\n## What This Notebook Does\nThis notebook calculates **FINZ climate alignment coverage** - the percentage of your investment portfolio that holds companies with validated 1.5Â°C Science Based Targets.\n\n---\n\n## FINZ Climate Alignment Assessment\n\nPer the **FINZ Standard Table 4.2**, this notebook outputs climate alignment categorization using **SBTi Target Status** as the \"In Transition\" methodology:\n\n| Category | Definition |\n|----------|------------|\n| **In Transition** | Companies with validated 1.5Â°C SBTi targets |\n| **Assessed** | All other companies (including WB2Â°C, 2Â°C, or no target) |\n\n**Coverage Metrics (no weighting, simple per-entity basis):**\n- **$ Coverage** = Investment value in category / Total portfolio value\n- **# Coverage** = Number of companies in category / Total company count\n\nThe granular **target classification** (1.5Â°C, WB2Â°C, 2Â°C, etc.) is preserved in the output for detailed analysis.\n\n> **Note:** This notebook uses SBTi 1.5Â°C Target Status as the sole \"In Transition\" methodology. \n> Full FINZ.Metric.2 calculation would also include other third-party methodologies (MSCI ITR, TPI, etc.), \n> taxonomy alignment (\"Climate Solutions\"), and verified GHG inventories (\"Net-zero State\").\n\n---\n\n## How to Use This Notebook\n\n### Step 1: Run the Setup\nRun the first few cells to install packages and load sample data.\n\n### Step 2: Upload Your Data (optional)\nTo analyze your own portfolio:\n\n| Environment | How to Upload |\n|-------------|---------------|\n| **Google Colab** | Click folder icon in left sidebar > Navigate to `data/` > Drag & drop your file |\n| **Local/Jupyter** | Copy your file to the `examples/data/` folder in your notebook directory |\n\nThen update the file path in the \"Load Your Portfolio\" section.\n\n### Step 3: Run All Cells\n- **Google Colab:** Click **Runtime > Run all** from the menu\n- **Local/Jupyter:** Click **Cell > Run All** or use keyboard shortcut (Shift+Enter for each cell)\n\n### Step 4: Download Results\nYour results will be saved as an Excel file in the `data/` folder with:\n- **Portfolio sheet:** Per-company FINZ alignment categorization with target classification\n- **Summary sheet:** Coverage by $ value and # companies\n\n---\n\n## Required Data Format\nYour portfolio file needs these columns:\n\n| Column | Required | Example | Description |\n|--------|----------|---------|-------------|\n| `company_name` | Yes | \"Apple Inc.\" | Company name for matching |\n| `company_id` | Yes | \"AAPL\" | Your internal identifier |\n| `investment_value` | Yes | 1000000 | Investment amount (any currency) |\n| `isin` | Recommended | \"US0378331005\" | International Securities ID (improves match accuracy) |\n| `lei` | Recommended | \"HWUPKR0MPOU8FGXBT394\" | Legal Entity Identifier (most reliable match) |\n\n**Tip:** Including ISIN and/or LEI significantly improves matching accuracy compared to company name alone.\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cea97d",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SETUP - Run this cell first\n# =============================================================================\n\nimport sys\n\n# Detect environment and install/import accordingly\nif 'google.colab' in sys.modules:\n    print(\"=\" * 50)\n    print(\"  GOOGLE COLAB ENVIRONMENT DETECTED\")\n    print(\"=\" * 50)\n    print(\"\\nInstalling SBTi Finance Tool...\")\n    !pip install -q sbti-finance-tool\n    print(\"âœ“ Installation complete\")\nelse:\n    print(\"=\" * 50)\n    print(\"  LOCAL/JUPYTER ENVIRONMENT DETECTED\")\n    print(\"=\" * 50)\n    print(\"\\nUsing locally installed packages\")\n    print(\"Tip: Run 'pip install sbti-finance-tool' if not installed\")\n\n# Import required libraries\nimport pandas as pd\nimport openpyxl\nfrom datetime import datetime\nimport os\nimport re\nimport warnings\n\n# Suppress common warnings for cleaner output\nwarnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\nprint(\"\\nâœ“ All packages loaded successfully\")\nprint(f\"\\nEnvironment: {'Google Colab' if 'google.colab' in sys.modules else 'Local/Jupyter'}\")\nprint(\"Ready to proceed!\")"
  },
  {
   "cell_type": "markdown",
   "id": "27951a88",
   "metadata": {},
   "source": [
    "## Download Sample Data\nThis cell downloads example data so you can test the notebook. Skip this if using your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be5a39",
   "metadata": {},
   "outputs": [],
   "source": "# Download sample portfolio data\nimport urllib.request\n\nif not os.path.isdir(\"data\"):\n    os.mkdir(\"data\")\n    \nif not os.path.isfile(\"data/example_portfolio.csv\"):\n    urllib.request.urlretrieve(\n        \"https://github.com/ScienceBasedTargets/SBTi-finance-tool/raw/main/examples/data/example_portfolio.csv\", \n        \"data/example_portfolio.csv\"\n    )\n    print(\"Sample data downloaded to data/example_portfolio.csv\")\nelse:\n    print(\"Sample data already exists\")"
  },
  {
   "cell_type": "markdown",
   "id": "26e2984b",
   "metadata": {},
   "source": "## USER INPUT: Load Your Portfolio\n\n### Option 1: Use Sample Data (Default)\nJust run the next cell as-is to use the included example portfolio.\n\n### Option 2: Use Your Own Data\n\n**Google Colab:**\n1. Click the folder icon (ðŸ“) in the left sidebar\n2. Navigate to `data/` folder  \n3. Drag and drop your CSV or Excel file\n4. Update the filename in the cell below\n\n**Local/Jupyter:**\n1. Copy your file to the `examples/data/` folder\n2. Update the filename in the cell below\n\n**Supported formats:** `.csv`, `.xlsx`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff216a",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# LOAD PORTFOLIO DATA\n# =============================================================================\n\n# --- SAMPLE DATA (default) ---\ndf_portfolio = pd.read_csv(\"data/example_portfolio.csv\", encoding=\"iso-8859-1\")\n\n# --- YOUR OWN DATA ---\n# Uncomment ONE of the lines below and update the filename:\n#\n# For CSV files:\n# df_portfolio = pd.read_csv(\"data/YOUR_FILE.csv\", encoding=\"utf-8\")\n#\n# For Excel files:\n# df_portfolio = pd.read_excel(\"data/YOUR_FILE.xlsx\", engine=\"openpyxl\")\n\nprint(f\"Loaded portfolio file successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def42bae",
   "metadata": {},
   "outputs": [],
   "source": "# Standardize column names (handles different naming formats automatically)\ndef convert_to_snake_case(name):\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n    s2 = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1)\n    s3 = s2.lower()\n    s4 = re.sub(r'[^a-z0-9_]', '_', s3)\n    s5 = re.sub(r'_+', '_', s4)\n    return s5.strip('_')\n\ndf_portfolio.columns = [convert_to_snake_case(col) for col in df_portfolio.columns]\nprint(f\"Loaded {len(df_portfolio)} companies from portfolio\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874da22f",
   "metadata": {},
   "outputs": [],
   "source": "# Auto-detect column formats (ISIN, LEI identifiers)\nportfolio_isin_col = next((c for c in ['company_isin', 'isin'] if c in df_portfolio.columns), None)\nportfolio_lei_col = next((c for c in ['company_lei', 'lei'] if c in df_portfolio.columns), None)\n\n# Show what identifiers were found\nid_status = []\nif portfolio_isin_col:\n    id_status.append(\"ISIN\")\nif portfolio_lei_col:\n    id_status.append(\"LEI\")\nif id_status:\n    print(f\"Company identifiers found: {', '.join(id_status)}\")\nelse:\n    print(\"Warning: No ISIN or LEI columns found - will match by company name only\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2c5b0",
   "metadata": {},
   "outputs": [],
   "source": "# Validate portfolio data\nrequired_cols = ['company_name', 'company_id', 'investment_value']\nmissing_cols = [col for col in required_cols if col not in df_portfolio.columns]\n\nif missing_cols:\n    print(f\"ERROR: Missing required columns: {missing_cols}\")\n    print(f\"Your file needs: company_name, company_id, investment_value\")\n    raise ValueError(f\"Missing columns: {missing_cols}\")\nelse:\n    total_value = df_portfolio['investment_value'].sum()\n    print(f\"Portfolio validated: {len(df_portfolio)} companies, ${total_value:,.0f} total value\")"
  },
  {
   "cell_type": "markdown",
   "id": "d6a9a87f",
   "metadata": {},
   "source": [
    "## USER INPUT: Select Analysis Date\n\nChoose the date for your analysis. This determines which SBTi targets are included (only targets published by this date).\n\n**Default:** December 31, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2025 #enter the year for which you want to calculate the portfolio coverage\n",
    "month = 12 #enter the month for which you want to calculate the portfolio coverage\n",
    "day = 31 #enter the day for which you want to calculate the portfolio coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_date = datetime(year, month, day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22aea59",
   "metadata": {},
   "source": [
    "## Loading SBTi Database\nThe tool automatically downloads the latest list of companies with validated Science Based Targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa2c59",
   "metadata": {},
   "outputs": [],
   "source": "# Load SBTi Companies Taking Action database\nfrom SBTi.data.sbti import SBTi\n\nprint(\"Loading SBTi database (this may take a moment)...\")\nsbti_provider = SBTi()\ncta_file = sbti_provider.targets.copy()\n\n# Count unique companies with targets\ncompanies_with_targets_count = len(cta_file[cta_file[sbti_provider.c.COL_ACTION] == sbti_provider.c.VALUE_ACTION_TARGET][sbti_provider.c.COL_COMPANY_NAME].unique())\nprint(f\"Loaded SBTi database: {companies_with_targets_count:,} companies with validated targets\")"
  },
  {
   "cell_type": "markdown",
   "id": "3d9b7815",
   "metadata": {},
   "source": [
    "## Processing Data\nFiltering SBTi data to match your analysis date..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9eac4",
   "metadata": {},
   "outputs": [],
   "source": "# Filter for companies with validated targets\ntargets = cta_file.copy()\ncompanies_with_targets = targets[targets[sbti_provider.c.COL_ACTION] == sbti_provider.c.VALUE_ACTION_TARGET]\n\nprint(f\"Processing {len(companies_with_targets[sbti_provider.c.COL_COMPANY_NAME].unique()):,} companies with SBT targets\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693fca3",
   "metadata": {},
   "outputs": [],
   "source": "# Handle date column format variations (contingency for different CTA formats)\ndate_col = sbti_provider.c.COL_DATE_PUBLISHED\npotential_date_cols = ['date_updated', 'Date Updated', 'date_published', 'Date Published']\n\n# Check if expected date column exists, otherwise search for alternatives\nif date_col not in companies_with_targets.columns:\n    found_date_col = next((col for col in potential_date_cols if col in companies_with_targets.columns), None)\n    if found_date_col:\n        companies_with_targets = companies_with_targets.rename(columns={found_date_col: date_col})\n        print(f\"Date column mapped: '{found_date_col}' -> '{date_col}'\")\n    else:\n        print(f\"WARNING: No date column found. Available columns: {list(companies_with_targets.columns)}\")\n        print(\"Date filtering will be skipped.\")\nelse:\n    print(f\"Date column: '{date_col}'\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e985555",
   "metadata": {},
   "outputs": [],
   "source": "# Apply date filter\ndf_targets = companies_with_targets.copy()\ndf_targets[sbti_provider.c.COL_DATE_PUBLISHED] = pd.to_datetime(df_targets[sbti_provider.c.COL_DATE_PUBLISHED])\n\n# Filter by user-specified date\ndate_filtered_df = df_targets.loc[df_targets[sbti_provider.c.COL_DATE_PUBLISHED] <= user_date]\n\n# Name normalization function (handles whitespace variations)\ndef normalize_name(name):\n    \"\"\"Normalize company name for matching: lowercase, collapse whitespace.\"\"\"\n    if pd.isna(name):\n        return None\n    return ' '.join(str(name).lower().split())\n\n# Create normalized company name set from ALL date-filtered companies\ndate_filtered_df['company_name_normalized'] = date_filtered_df[sbti_provider.c.COL_COMPANY_NAME].apply(normalize_name)\ncompany_name_set = set(date_filtered_df['company_name_normalized'].dropna())\n\n# Create ISIN/LEI sets only from companies that have these identifiers\nisin_set = set(date_filtered_df[sbti_provider.c.COL_COMPANY_ISIN].dropna())\nlei_set = set(date_filtered_df[sbti_provider.c.COL_COMPANY_LEI].dropna())\n\n# Keep filtered_df for 1.5C analysis\nfiltered_df = date_filtered_df.copy()\n\nprint(f\"Filtered to targets published by {user_date.strftime('%B %d, %Y')}\")\nprint(f\"  - Companies for name matching: {len(company_name_set):,}\")\nprint(f\"  - Unique ISINs: {len(isin_set):,}\")\nprint(f\"  - Unique LEIs: {len(lei_set):,}\")"
  },
  {
   "cell_type": "markdown",
   "id": "666b6418",
   "metadata": {},
   "source": [
    "## Matching Your Portfolio\nNow matching your portfolio companies against the SBTi database..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ba904",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# COMPANY MATCHING UTILITIES\n# =============================================================================\n\ndef match_company(row, target_isin_set, target_lei_set, target_name_set):\n    \"\"\"\n    Match a portfolio company against a set of target companies.\n    \n    Returns the match method ('LEI', 'ISIN', 'Name') or None if no match.\n    \n    Priority order (highest reliability first):\n    1. LEI match (Legal Entity Identifier - most reliable)\n    2. ISIN match (International Securities ID - very reliable)\n    3. Company name match (normalized, case-insensitive - fallback)\n    \"\"\"\n    # Check LEI first (most reliable identifier)\n    if portfolio_lei_col and pd.notna(row.get(portfolio_lei_col)):\n        if row.get(portfolio_lei_col) in target_lei_set:\n            return 'LEI'\n\n    # Check ISIN second (very reliable)\n    if portfolio_isin_col and pd.notna(row.get(portfolio_isin_col)):\n        if row.get(portfolio_isin_col) in target_isin_set:\n            return 'ISIN'\n\n    # Check company name last (normalized match)\n    if pd.notna(row.get('company_name')):\n        # Use same normalization as CTA names\n        normalized_name = normalize_name(row.get('company_name'))\n        if normalized_name and normalized_name in target_name_set:\n            return 'Name'\n\n    return None\n\n\ndef get_target_classification(row, target_df, classification_col):\n    \"\"\"\n    Look up the target classification for a matched portfolio company.\n    \n    Uses waterfall matching: LEI > ISIN > Company Name (exact match after normalization)\n    \n    Returns the target classification (e.g., '1.5Â°C', 'Well-below 2Â°C', '2Â°C') or None.\n    \"\"\"\n    # Check LEI first\n    if portfolio_lei_col and pd.notna(row.get(portfolio_lei_col)):\n        matches = target_df[target_df[sbti_provider.c.COL_COMPANY_LEI] == row.get(portfolio_lei_col)]\n        if len(matches) > 0:\n            classification = matches.iloc[0][classification_col]\n            if pd.notna(classification):\n                return str(classification)\n    \n    # Check ISIN second\n    if portfolio_isin_col and pd.notna(row.get(portfolio_isin_col)):\n        matches = target_df[target_df[sbti_provider.c.COL_COMPANY_ISIN] == row.get(portfolio_isin_col)]\n        if len(matches) > 0:\n            classification = matches.iloc[0][classification_col]\n            if pd.notna(classification):\n                return str(classification)\n    \n    # Check company name last (normalized exact match)\n    if pd.notna(row.get('company_name')):\n        normalized_name = normalize_name(row.get('company_name'))\n        if normalized_name:\n            matches = target_df[target_df['company_name_normalized'] == normalized_name]\n            if len(matches) > 0:\n                classification = matches.iloc[0][classification_col]\n                if pd.notna(classification):\n                    return str(classification)\n    \n    return None\n\n\n# =============================================================================\n# VALIDATE PORTFOLIO AGAINST ALL SBT TARGETS (DATE-FILTERED) - FINT\n# =============================================================================\n\n# Apply matching to determine if company has validated SBT target\ndf_portfolio['match_method_all'] = df_portfolio.apply(\n    lambda row: match_company(row, isin_set, lei_set, company_name_set), \n    axis=1\n)\ndf_portfolio['validated'] = df_portfolio['match_method_all'].notna()\n\n# Diagnostic: Show match method breakdown\nmatch_counts = df_portfolio['match_method_all'].value_counts()\ntotal_matched = df_portfolio['validated'].sum()\ntotal_companies = len(df_portfolio)\n\nprint(f\"SBT Matching (FINT): {total_matched} / {total_companies} companies matched\")\nprint(f\"  Match breakdown:\")\nfor method in ['LEI', 'ISIN', 'Name']:\n    count = match_counts.get(method, 0)\n    if count > 0:\n        print(f\"    - {method}: {count}\")"
  },
  {
   "cell_type": "markdown",
   "id": "15c_config",
   "metadata": {},
   "source": "## USER INPUT: 1.5Â°C Target Settings (Optional)\n\n**What is a 1.5Â°C target?** Companies with the most ambitious climate commitments, aligned with limiting global warming to 1.5Â°C. These are the only targets that count toward **FINZ (FI Net-Zero Standard)** coverage.\n\n**Default settings work for most users.** Only change if you need specific filtering."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c_settings",
   "metadata": {},
   "outputs": [],
   "source": "# 1.5Â°C Target Configuration (most users can leave defaults)\n# --------------------------------------------------------\n# INCLUDE_PURE_15C = True   -> Count companies with pure 1.5Â°C targets\n# INCLUDE_MIXED_15C_2C = False -> Exclude mixed targets like \"1.5Â°C/2Â°C\"\n\nINCLUDE_PURE_15C = True        # Recommended: True\nINCLUDE_MIXED_15C_2C = False   # Recommended: False (more conservative)\n\nprint(f\"1.5Â°C settings: Pure={INCLUDE_PURE_15C}, Mixed={INCLUDE_MIXED_15C_2C}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b838de2",
   "metadata": {},
   "outputs": [],
   "source": "# Identify 1.5Â°C aligned companies in SBTi database (for FINZ coverage)\ndf_analysis = filtered_df.copy()\n\n# Find Target Classification column (handle potential naming variations)\nTARGET_CLASSIFICATION_COL = None\npotential_tc_cols = ['Target Classification', 'target_classification', 'Near Term Classification', \n                     'near_term_target_classification', 'target_classification_short']\nfor col in potential_tc_cols:\n    if col in df_analysis.columns:\n        TARGET_CLASSIFICATION_COL = col\n        break\n\nif TARGET_CLASSIFICATION_COL is None:\n    print(\"ERROR: No Target Classification column found!\")\n    print(f\"Available columns: {list(df_analysis.columns)}\")\n    raise ValueError(\"Missing Target Classification column\")\n\n# Show available classification values for transparency\nunique_classifications = df_analysis[TARGET_CLASSIFICATION_COL].dropna().unique()\nprint(f\"Target Classification column: '{TARGET_CLASSIFICATION_COL}'\")\nprint(f\"Classifications found: {sorted([str(x) for x in unique_classifications])}\")\n\n# Define known 1.5Â°C classification patterns (per FINZ Implementation List Table 1)\nPURE_15C_VALUES = ['1.5Â°C', '1.5Â°C/1.5Â°C']  # Pure 1.5Â°C (both near-term and long-term)\nMIXED_15C_PATTERNS = ['1.5Â°C/Well-below 2Â°C', '1.5Â°C/2Â°C', '1.5/']  # Mixed with other temps\n\n# Filter for 1.5Â°C targets based on settings\ndf_1_5c = pd.DataFrame()\n\nif INCLUDE_PURE_15C:\n    # Match known pure 1.5Â°C values\n    pure_mask = df_analysis[TARGET_CLASSIFICATION_COL].isin(PURE_15C_VALUES)\n    pure_15c = df_analysis[pure_mask]\n    df_1_5c = pd.concat([df_1_5c, pure_15c])\n    print(f\"  Pure 1.5Â°C matches: {len(pure_15c)} rows\")\n    \n    # Check for unexpected pure 1.5Â°C patterns (safety check)\n    unexpected_pure = df_analysis[\n        (df_analysis[TARGET_CLASSIFICATION_COL].astype(str).str.startswith('1.5Â°C')) &\n        (~df_analysis[TARGET_CLASSIFICATION_COL].isin(PURE_15C_VALUES)) &\n        (~df_analysis[TARGET_CLASSIFICATION_COL].astype(str).str.contains('/', na=False))\n    ]\n    if len(unexpected_pure) > 0:\n        print(f\"  WARNING: Found {len(unexpected_pure)} rows with unexpected 1.5Â°C pattern\")\n        print(f\"           Values: {unexpected_pure[TARGET_CLASSIFICATION_COL].unique()}\")\n    \nif INCLUDE_MIXED_15C_2C:\n    # Match mixed classifications containing 1.5Â°C with other temps\n    mixed_mask = (\n        (df_analysis[TARGET_CLASSIFICATION_COL].astype(str).str.contains('1.5', na=False)) &\n        (df_analysis[TARGET_CLASSIFICATION_COL].astype(str).str.contains('/', na=False)) &\n        (~df_analysis[TARGET_CLASSIFICATION_COL].isin(PURE_15C_VALUES))\n    )\n    mixed = df_analysis[mixed_mask]\n    df_1_5c = pd.concat([df_1_5c, mixed])\n    print(f\"  Mixed 1.5Â°C matches: {len(mixed)} rows\")\n\n# Create lookup sets for 1.5Â°C matching\nif len(df_1_5c) > 0:\n    # Deduplicate by company name to count unique companies\n    df_1_5c_unique = df_1_5c.drop_duplicates(subset=[sbti_provider.c.COL_COMPANY_NAME])\n    \n    # Create ISIN/LEI sets from companies that have these identifiers\n    isin_set_1_5c = set(df_1_5c[sbti_provider.c.COL_COMPANY_ISIN].dropna())\n    lei_set_1_5c = set(df_1_5c[sbti_provider.c.COL_COMPANY_LEI].dropna())\n    \n    # Create normalized name set from ALL 1.5Â°C companies\n    company_name_set_1_5c = set(df_1_5c[sbti_provider.c.COL_COMPANY_NAME].apply(normalize_name).dropna())\n    \n    print(f\"Found {len(df_1_5c_unique):,} unique companies with 1.5Â°C targets (FINZ eligible)\")\n    print(f\"  - For name matching: {len(company_name_set_1_5c):,}\")\n    print(f\"  - With ISIN: {len(isin_set_1_5c):,}\")\n    print(f\"  - With LEI: {len(lei_set_1_5c):,}\")\nelse:\n    isin_set_1_5c, lei_set_1_5c, company_name_set_1_5c = set(), set(), set()\n    print(\"Warning: No 1.5Â°C companies found with current settings\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d2ba7a",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MATCH PORTFOLIO COMPANIES TO 1.5Â°C ALIGNED COMPANIES (FINZ)\n# =============================================================================\n\n# Apply matching using the reusable match_company function\ndf_portfolio['match_method_1_5c'] = df_portfolio.apply(\n    lambda row: match_company(row, isin_set_1_5c, lei_set_1_5c, company_name_set_1_5c), \n    axis=1\n)\ndf_portfolio['is_1_5c'] = df_portfolio['match_method_1_5c'].notna()\n\n# =============================================================================\n# LOOK UP TARGET CLASSIFICATION FOR MATCHED COMPANIES\n# =============================================================================\n\n# Look up target classification for each portfolio company that matched\ndf_portfolio['target_classification'] = df_portfolio.apply(\n    lambda row: get_target_classification(row, date_filtered_df, TARGET_CLASSIFICATION_COL) if row['validated'] else None,\n    axis=1\n)\n\n# Diagnostic: Show 1.5Â°C match method breakdown\nmatch_counts_15c = df_portfolio['match_method_1_5c'].value_counts()\ntotal_matched_15c = df_portfolio['is_1_5c'].sum()\ntotal_portfolio_companies = len(df_portfolio)\n\nprint(f\"1.5Â°C Matching (FINZ): {total_matched_15c} / {total_portfolio_companies} companies\")\nif total_matched_15c > 0:\n    print(f\"  Match breakdown:\")\n    for method in ['LEI', 'ISIN', 'Name']:\n        count = match_counts_15c.get(method, 0)\n        if count > 0:\n            print(f\"    - {method}: {count}\")\n\n# Show target classification breakdown for matched companies\nprint(f\"\\nTarget Classifications found:\")\nclassification_counts = df_portfolio['target_classification'].value_counts()\nfor classification, count in classification_counts.items():\n    print(f\"    - {classification}: {count}\")"
  },
  {
   "cell_type": "markdown",
   "id": "58b1d787",
   "metadata": {},
   "source": "---\n# Your Results: FINZ Climate Alignment Assessment\n\nThe following sections show your portfolio's **FINZ climate alignment** based on SBTi 1.5Â°C Target Status.\n\n**FINZ Alignment Categories (per Table 4.2):**\n- **In Transition** â€” Companies with validated 1.5Â°C SBTi targets\n- **Assessed** â€” All other companies (including WB2Â°C, 2Â°C, or no validated target)\n\n**Coverage is calculated on a simple per-entity basis (no weighting):**\n- **$ Coverage** = Sum of investment values / Total portfolio value\n- **# Coverage** = Count of companies / Total company count\n\n> **Methodology:** This assessment uses **SBTi 1.5Â°C Target Status** as the \"In Transition\" methodology per FINZ Implementation List Table 1."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc0aa5",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CALCULATE FINZ COVERAGE METRICS (No Weighting - Simple Per-Entity Basis)\n# =============================================================================\n\ntotal_investment_value = df_portfolio['investment_value'].sum()\ntotal_companies = len(df_portfolio)\ndistinct_company_count = df_portfolio['company_name'].nunique()\n\n# In Transition: 1.5Â°C targets only\nin_transition_value = df_portfolio.loc[df_portfolio['is_1_5c'] == True, 'investment_value'].sum()\nin_transition_count = df_portfolio['is_1_5c'].sum()\n\n# Assessed: Everything else (including WB2Â°C, 2Â°C, and no target)\nassessed_value = total_investment_value - in_transition_value\nassessed_count = total_companies - in_transition_count\n\n# Calculate percentages (simple $ and # coverage, no weighting)\nin_transition_value_pct = (in_transition_value / total_investment_value * 100) if total_investment_value > 0 else 0\nin_transition_count_pct = (in_transition_count / total_companies * 100) if total_companies > 0 else 0\n\nassessed_value_pct = (assessed_value / total_investment_value * 100) if total_investment_value > 0 else 0\nassessed_count_pct = (assessed_count / total_companies * 100) if total_companies > 0 else 0\n\n# Display results\nprint(\"=\" * 75)\nprint(\"           FINZ CLIMATE ALIGNMENT ASSESSMENT SUMMARY\")\nprint(\"=\" * 75)\nprint(f\"\\nTotal Portfolio Value: ${total_investment_value:,.0f}\")\nprint(f\"Total Companies: {total_companies}\")\n\nprint(f\"\\n\" + \"=\" * 75)\nprint(\"  COVERAGE BY CATEGORY (No Weighting - Simple Per-Entity Basis)\")\nprint(\"=\" * 75)\n\nprint(f\"\\n  IN TRANSITION (1.5Â°C validated SBTi targets)\")\nprint(f\"  \" + \"-\" * 60)\nprint(f\"    $ Coverage:  ${in_transition_value:,.0f} / ${total_investment_value:,.0f} = {in_transition_value_pct:.1f}%\")\nprint(f\"    # Coverage:  {in_transition_count} / {total_companies} = {in_transition_count_pct:.1f}%\")\n\nprint(f\"\\n  ASSESSED (All other companies)\")\nprint(f\"  \" + \"-\" * 60)\nprint(f\"    $ Coverage:  ${assessed_value:,.0f} / ${total_investment_value:,.0f} = {assessed_value_pct:.1f}%\")\nprint(f\"    # Coverage:  {assessed_count} / {total_companies} = {assessed_count_pct:.1f}%\")\n\nprint(f\"\\n\" + \"=\" * 75)\nprint(\"  TARGET CLASSIFICATION BREAKDOWN (Granular Detail)\")\nprint(\"=\" * 75)\nclassification_breakdown = df_portfolio.groupby('target_classification').agg({\n    'investment_value': 'sum',\n    'company_name': 'count'\n}).rename(columns={'company_name': 'count'})\nclassification_breakdown['value_pct'] = classification_breakdown['investment_value'] / total_investment_value * 100\nclassification_breakdown['count_pct'] = classification_breakdown['count'] / total_companies * 100\n\n# Add \"No Target\" row for companies without classification\nno_target_value = df_portfolio.loc[df_portfolio['target_classification'].isna(), 'investment_value'].sum()\nno_target_count = df_portfolio['target_classification'].isna().sum()\nif no_target_count > 0:\n    print(f\"\\n  {'Classification':<25} {'$ Value':>15} {'$ %':>8} {'# Co.':>8} {'# %':>8}\")\n    print(f\"  \" + \"-\" * 65)\n    for classification, row in classification_breakdown.iterrows():\n        if pd.notna(classification):\n            print(f\"  {str(classification):<25} ${row['investment_value']:>13,.0f} {row['value_pct']:>7.1f}% {int(row['count']):>8} {row['count_pct']:>7.1f}%\")\n    print(f\"  {'(No Target)':<25} ${no_target_value:>13,.0f} {no_target_value/total_investment_value*100:>7.1f}% {no_target_count:>8} {no_target_count/total_companies*100:>7.1f}%\")\nelse:\n    print(f\"\\n  {'Classification':<25} {'$ Value':>15} {'$ %':>8} {'# Co.':>8} {'# %':>8}\")\n    print(f\"  \" + \"-\" * 65)\n    for classification, row in classification_breakdown.iterrows():\n        print(f\"  {str(classification):<25} ${row['investment_value']:>13,.0f} {row['value_pct']:>7.1f}% {int(row['count']):>8} {row['count_pct']:>7.1f}%\")\n\nprint(f\"\\n\" + \"=\" * 75)"
  },
  {
   "cell_type": "code",
   "id": "consolidated_summary",
   "metadata": {},
   "source": "# =============================================================================\n# VISUAL SUMMARY - FINZ Climate Alignment Assessment (2 Categories)\n# =============================================================================\n\nimport matplotlib.pyplot as plt\n\n# Import FINZ alignment categories from the library\nfrom SBTi.interfaces import FINZAlignmentCategory\n\n# Classify each company per FINZ alignment categories (Table 4.2)\n# FINZ only has 2 categories: In Transition (1.5Â°C) and Assessed (everything else)\ndef get_finz_alignment(row):\n    \"\"\"\n    Classify company climate alignment per FINZ Standard Table 4.2.\n    \n    Uses SBTi 1.5Â°C Target Status as the \"In Transition\" methodology\n    per FINZ Implementation List Table 1.\n    \n    - In Transition: 1.5Â°C validated SBTi targets\n    - Assessed: All other companies (WB2Â°C, 2Â°C, no target)\n    \"\"\"\n    if row['is_1_5c']:\n        return FINZAlignmentCategory.IN_TRANSITION.value\n    else:\n        return FINZAlignmentCategory.ASSESSED.value\n\ndf_portfolio['finz_category'] = df_portfolio.apply(get_finz_alignment, axis=1)\n\n# Calculate values for chart (2 categories only)\nalignment_values = df_portfolio.groupby('finz_category')['investment_value'].sum()\n\n# Ensure order: In Transition, Assessed (2 categories)\ncategories = [\n    FINZAlignmentCategory.IN_TRANSITION.value, \n    FINZAlignmentCategory.ASSESSED.value\n]\nvalues = [alignment_values.get(cat, 0) for cat in categories]\ncolors = ['#2ecc71', '#95a5a6']  # Green, Gray\n\n# Create charts\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\nfig.suptitle('FINZ Climate Alignment Assessment', fontsize=16, fontweight='bold', y=1.02)\n\n# Pie chart by value\nwedges, texts, autotexts = ax1.pie(\n    values, \n    labels=categories, \n    autopct=lambda pct: f'{pct:.1f}%' if pct > 0 else '',\n    colors=colors,\n    startangle=90\n)\nax1.set_title('Portfolio by Investment Value ($)', fontsize=14, fontweight='bold')\n\n# Bar chart by company count\ncounts = df_portfolio.groupby('finz_category')['company_name'].count()\ncount_values = [counts.get(cat, 0) for cat in categories]\n\nbars = ax2.bar(categories, count_values, color=colors)\nax2.set_ylabel('Number of Companies')\nax2.set_title('Portfolio by Company Count (#)', fontsize=14, fontweight='bold')\n\n# Add value labels on bars\nfor bar, count in zip(bars, count_values):\n    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n             str(count), ha='center', va='bottom', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Print summary table with both $ and # coverage\nprint(\"\\n\" + \"=\" * 80)\nprint(\"              FINZ CLIMATE ALIGNMENT ASSESSMENT\")\nprint(\"=\" * 80)\nprint(f\"\\nMethodology: SBTi 1.5Â°C Target Status (per FINZ Implementation List Table 1)\")\nprint(f\"Coverage Basis: Simple per-entity (no weighting)\")\nprint(f\"\\n{'Category':<18} {'$ Value':>15} {'$ %':>10} {'# Companies':>15} {'# %':>10}\")\nprint(\"-\" * 80)\nfor cat, val, cnt in zip(categories, values, count_values):\n    val_pct = (val / total_investment_value * 100) if total_investment_value > 0 else 0\n    cnt_pct = (cnt / total_companies * 100) if total_companies > 0 else 0\n    print(f\"{cat:<18} ${val:>13,.0f} {val_pct:>9.1f}% {cnt:>15} {cnt_pct:>9.1f}%\")\nprint(\"-\" * 80)\nprint(f\"{'TOTAL':<18} ${total_investment_value:>13,.0f} {'100.0':>9}% {total_companies:>15} {'100.0':>9}%\")\n\nprint(\"\\n\" + \"-\" * 80)\nprint(\"FINZ COVERAGE (In Transition only):\")\nprint(f\"  $ Coverage: {in_transition_value_pct:.1f}% (${in_transition_value:,.0f} / ${total_investment_value:,.0f})\")\nprint(f\"  # Coverage: {in_transition_count_pct:.1f}% ({in_transition_count} / {total_companies} companies)\")\nprint(\"\\n  Note: Only 'In Transition' (1.5Â°C targets) counts toward FINZ alignment.\")\nprint(\"        The granular target classification is preserved in the output file.\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "52847be1",
   "metadata": {},
   "source": "---\n# Download Your Results\n\nRun the cell below to save your results as an Excel file.\n\n## Output File\n**Filename:** `portfolio_climate_alignment.xlsx`  \n**Location:** `data/` folder\n\n## How to Access Your File\n\n| Environment | Instructions |\n|-------------|--------------|\n| **Google Colab** | 1. Click folder icon in left sidebar<br>2. Navigate to `data/` folder<br>3. Right-click `portfolio_climate_alignment.xlsx`<br>4. Select **Download** |\n| **Local/Jupyter** | File is saved to the `examples/data/` folder in your notebook directory. The full path will be shown in the output below. |\n\n## What's Included\n\n| Sheet | Contents |\n|-------|----------|\n| **Portfolio** | Per-company data with FINZ alignment category (`In Transition` or `Assessed`) and granular target classification |\n| **Summary** | Coverage metrics: $ value and # companies for each category |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd0a60",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SAVE RESULTS TO EXCEL - FINZ Climate Alignment Assessment (2 Categories)\n# =============================================================================\n\noutput_filename = 'portfolio_climate_alignment'\noutput_dir = 'data'\n\nif not os.path.isdir(output_dir):\n    os.mkdir(output_dir)\n\n# Prepare clean export data with FINZ alignment categories and target classification\nexport_columns = ['company_id', 'company_name', 'investment_value', 'finz_category', 'target_classification', 'match_method_all']\nif portfolio_isin_col:\n    export_columns.insert(3, portfolio_isin_col)\nif portfolio_lei_col:\n    export_columns.insert(3, portfolio_lei_col)\n\nexport_columns = [c for c in export_columns if c in df_portfolio.columns]\ndf_export = df_portfolio[export_columns].copy()\n\n# Rename columns for clearer output\ncolumn_renames = {\n    'match_method_all': 'match_method',\n    'finz_category': 'finz_alignment_category'\n}\ndf_export = df_export.rename(columns={k: v for k, v in column_renames.items() if k in df_export.columns})\n\n# Create summary data with FINZ alignment assessment output (2 categories, $ and # coverage)\nsummary_data = {\n    'Metric': [\n        'FINZ CLIMATE ALIGNMENT ASSESSMENT', '', '',\n        'Analysis Date', 'Coverage Date', 'Methodology', 'Coverage Basis', '',\n        'PORTFOLIO TOTALS', '  Total Portfolio Value', '  Total Companies', '',\n        '--- COVERAGE BY CATEGORY ---', '', '',\n        f'{FINZAlignmentCategory.IN_TRANSITION.value}', '  Definition', '  $ Value', '  $ Coverage %', '  # Companies', '  # Coverage %', '',\n        f'{FINZAlignmentCategory.ASSESSED.value}', '  Definition', '  $ Value', '  $ Coverage %', '  # Companies', '  # Coverage %', '',\n        '--- FINZ COVERAGE SUMMARY ---', '  $ Coverage (In Transition)', '  # Coverage (In Transition)'\n    ],\n    'Value': [\n        'SBTi 1.5Â°C Target Status Methodology', '', '',\n        datetime.now().strftime('%Y-%m-%d'), user_date.strftime('%Y-%m-%d'), 'SBTi Target Status (FINZ Implementation List Table 1)', 'Simple per-entity (no weighting)', '',\n        '', f\"${total_investment_value:,.0f}\", str(total_companies), '',\n        '', '', '',\n        '', '1.5Â°C validated SBTi targets', f\"${in_transition_value:,.0f}\", f\"{in_transition_value_pct:.1f}%\", str(in_transition_count), f\"{in_transition_count_pct:.1f}%\", '',\n        '', 'All other companies (WB2Â°C, 2Â°C, no target)', f\"${assessed_value:,.0f}\", f\"{assessed_value_pct:.1f}%\", str(assessed_count), f\"{assessed_count_pct:.1f}%\", '',\n        '', f\"{in_transition_value_pct:.1f}% (${in_transition_value:,.0f} / ${total_investment_value:,.0f})\", f\"{in_transition_count_pct:.1f}% ({in_transition_count} / {total_companies} companies)\"\n    ]\n}\n\n# Save to Excel\nexcel_path = f\"{output_dir}/{output_filename}.xlsx\"\n\nwith pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n    df_export.to_excel(writer, sheet_name='Portfolio', index=False)\n    pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)\n\n# Get absolute path for local users\nabs_path = os.path.abspath(excel_path)\n\nprint(\"=\" * 65)\nprint(\"     FINZ CLIMATE ALIGNMENT ASSESSMENT - SAVED\")\nprint(\"=\" * 65)\nprint(f\"\\nFile saved to: {excel_path}\")\nprint(f\"\\nContents:\")\nprint(f\"  - Portfolio sheet: Per-company FINZ alignment categories\")\nprint(f\"                     (In Transition or Assessed) + target classification\")\nprint(f\"  - Summary sheet: $ and # coverage metrics\")\n\nif 'google.colab' in sys.modules:\n    print(f\"\\n[Google Colab] To download your file:\")\n    print(f\"   1. Click the folder icon in the left sidebar\")\n    print(f\"   2. Navigate to 'data' folder\")\n    print(f\"   3. Right-click '{output_filename}.xlsx' > Download\")\nelse:\n    print(f\"\\n[Local] Full path: {abs_path}\")\n    print(f\"   Open this location in your file explorer to access the file.\")\n\nprint(\"\\n\" + \"=\" * 65)\n\n# Show preview with FINZ alignment category and target classification\nprint(f\"\\nPreview of exported data:\")\nprint(df_export.head(10).to_string(index=False))"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}